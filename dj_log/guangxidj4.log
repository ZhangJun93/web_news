2017-03-16 06:00:01 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: web_news)
2017-03-16 06:00:01 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'web_news.spiders', 'SPIDER_MODULES': ['web_news.spiders'], 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS_PER_DOMAIN': 32, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'CONCURRENT_REQUESTS': 32, 'METAREFRESH_ENABLED': False, 'CONCURRENT_REQUESTS_PER_IP': 32, 'BOT_NAME': 'web_news', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'REDIRECT_ENABLED': False, 'LOG_FILE': 'dj_log/guangxidj4.log', 'DOWNLOAD_DELAY': 0.25}
2017-03-16 06:00:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-03-16 06:00:01 [guangxidj] INFO: get key 1
2017-03-16 06:00:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-16 06:00:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-16 06:00:01 [scrapy.middleware] INFO: Enabled item pipelines:
['web_news.pipelines.MongoDBPipeline']
2017-03-16 06:00:01 [scrapy.core.engine] INFO: Spider opened
2017-03-16 06:00:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-16 06:00:05 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-16 06:00:05 [guangxidj] INFO: wait 6 spiders to stop
2017-03-16 06:00:05 [guangxidj] INFO: wait 5 spiders to stop
2017-03-16 06:00:05 [guangxidj] INFO: wait 4 spiders to stop
2017-03-16 06:00:05 [guangxidj] INFO: wait 3 spiders to stop
2017-03-16 06:00:05 [guangxidj] INFO: wait 2 spiders to stop
2017-03-16 06:00:05 [guangxidj] INFO: wait 1 spiders to stop
2017-03-16 06:00:05 [guangxidj] INFO: all slave spider exit
2017-03-16 06:00:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 564,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 41752,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 15, 22, 0, 5, 242930),
 'log_count/INFO': 15,
 'response_received_count': 2,
 'scheduler/dequeued/redis': 2,
 'scheduler/enqueued/redis': 1,
 'start_time': datetime.datetime(2017, 3, 15, 22, 0, 1, 846823)}
2017-03-16 06:00:05 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-17 06:00:02 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: web_news)
2017-03-17 06:00:02 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'web_news.spiders', 'SPIDER_MODULES': ['web_news.spiders'], 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS_PER_DOMAIN': 32, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'CONCURRENT_REQUESTS': 32, 'METAREFRESH_ENABLED': False, 'CONCURRENT_REQUESTS_PER_IP': 32, 'BOT_NAME': 'web_news', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'REDIRECT_ENABLED': False, 'LOG_FILE': 'dj_log/guangxidj4.log', 'DOWNLOAD_DELAY': 0.25}
2017-03-17 06:00:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-03-17 06:00:02 [twisted] ERROR: Unhandled error in Deferred:
2017-03-17 06:00:02 [twisted] ERROR: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/scrapy/commands/crawl.py", line 57, in run
    self.crawler_process.crawl(spname, **opts.spargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 163, in crawl
    return self._crawl(crawler, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 167, in _crawl
    d = crawler.crawl(*args, **kwargs)
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1237, in unwindGenerator
    return _inlineCallbacks(None, gen, Deferred())
--- <exception caught here> ---
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1099, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 90, in crawl
    six.reraise(*exc_info)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 71, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/crawler.py", line 94, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/u231/spider/web_news/misc/spiderredis.py", line 43, in from_crawler
    spider.compete_key()
  File "/home/u231/spider/web_news/misc/spiderredis.py", line 16, in compete_key
    while self.server.sadd(self.redis_compete, self.key) == 0:
  File "/usr/local/lib/python2.7/dist-packages/redis/client.py", line 1494, in sadd
    return self.execute_command('SADD', name, *values)
  File "/usr/local/lib/python2.7/dist-packages/redis/client.py", line 573, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "/usr/local/lib/python2.7/dist-packages/redis/client.py", line 585, in parse_response
    response = connection.read_response()
  File "/usr/local/lib/python2.7/dist-packages/redis/connection.py", line 582, in read_response
    raise response
redis.exceptions.ResponseError: OOM command not allowed when used memory > 'maxmemory'.

2017-03-18 06:00:02 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: web_news)
2017-03-18 06:00:02 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'web_news.spiders', 'SPIDER_MODULES': ['web_news.spiders'], 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS_PER_DOMAIN': 32, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'CONCURRENT_REQUESTS': 32, 'METAREFRESH_ENABLED': False, 'CONCURRENT_REQUESTS_PER_IP': 32, 'BOT_NAME': 'web_news', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'REDIRECT_ENABLED': False, 'LOG_FILE': 'dj_log/guangxidj4.log', 'DOWNLOAD_DELAY': 0.25}
2017-03-18 06:00:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-03-18 06:00:02 [guangxidj] INFO: get key 6
2017-03-18 06:00:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-18 06:00:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-18 06:00:02 [scrapy.middleware] INFO: Enabled item pipelines:
['web_news.pipelines.MongoDBPipeline']
2017-03-18 06:00:02 [scrapy.core.engine] INFO: Spider opened
2017-03-18 06:00:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-18 06:00:04 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11161.aspx
2017-03-18 06:00:05 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11159.aspx
2017-03-18 06:00:05 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11158.aspx
2017-03-18 06:00:06 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11157.aspx
2017-03-18 06:00:06 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11156.aspx
2017-03-18 06:00:06 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11155.aspx
2017-03-18 06:00:06 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11154.aspx
2017-03-18 06:00:07 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11153.aspx
2017-03-18 06:00:07 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11152.aspx
2017-03-18 06:00:08 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11151.aspx
2017-03-18 06:00:08 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11150.aspx
2017-03-18 06:00:08 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11147.aspx
2017-03-18 06:00:08 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11145.aspx
2017-03-18 06:00:09 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11127.aspx
2017-03-18 06:00:09 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11053.aspx
2017-03-18 06:00:09 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11146.aspx
2017-03-18 06:00:10 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11144.aspx
2017-03-18 06:00:10 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11143.aspx
2017-03-18 06:00:10 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11142.aspx
2017-03-18 06:00:11 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11141.aspx
2017-03-18 06:00:11 [guangxidj] ERROR: error url: http://www.gxjgdj.com/Item/11136.aspx error msg: expected string or buffer
2017-03-18 06:00:11 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11136.aspx
2017-03-18 06:00:11 [guangxidj] WARNING:  url: http://www.gxjgdj.com/Item/11136.aspx msg:  content is None
2017-03-18 06:00:11 [guangxidj] ERROR: error url: http://www.gxjgdj.com/Item/11115.aspx error msg: expected string or buffer
2017-03-18 06:00:11 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11115.aspx
2017-03-18 06:00:11 [guangxidj] WARNING:  url: http://www.gxjgdj.com/Item/11115.aspx msg:  content is None
2017-03-18 06:00:16 [guangxidj] ERROR: error url: http://www.gxjgdj.com/Item/11148.aspx error msg: expected string or buffer
2017-03-18 06:00:16 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11148.aspx
2017-03-18 06:00:16 [guangxidj] WARNING:  url: http://www.gxjgdj.com/Item/11148.aspx msg:  content is None
2017-03-18 06:00:16 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11140.aspx
2017-03-18 06:00:17 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11139.aspx
2017-03-18 06:00:18 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11138.aspx
2017-03-18 06:00:18 [guangxidj] INFO: crawling url: http://www.gxjgdj.com/Item/11137.aspx
2017-03-18 06:00:18 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-18 06:00:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16609,
 'downloader/request_count': 43,
 'downloader/request_method_count/GET': 43,
 'downloader/response_bytes': 395779,
 'downloader/response_count': 43,
 'downloader/response_status_count/200': 43,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 17, 22, 0, 18, 886461),
 'item_scraped_count': 27,
 'log_count/ERROR': 3,
 'log_count/INFO': 35,
 'log_count/WARNING': 3,
 'request_depth_max': 3,
 'response_received_count': 43,
 'scheduler/dequeued/redis': 43,
 'scheduler/enqueued/redis': 56,
 'start_time': datetime.datetime(2017, 3, 17, 22, 0, 2, 622349)}
2017-03-18 06:00:18 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-18 14:45:18 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: web_news)
2017-03-18 14:45:18 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'web_news.spiders', 'SPIDER_MODULES': ['web_news.spiders'], 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS_PER_DOMAIN': 32, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'CONCURRENT_REQUESTS': 32, 'METAREFRESH_ENABLED': False, 'CONCURRENT_REQUESTS_PER_IP': 32, 'BOT_NAME': 'web_news', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'REDIRECT_ENABLED': False, 'LOG_FILE': 'dj_log/guangxidj4.log', 'DOWNLOAD_DELAY': 0.25}
2017-03-18 14:45:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2017-03-18 14:45:18 [guangxidj] INFO: get key 1
2017-03-18 14:45:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-18 14:45:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-18 14:45:18 [scrapy.middleware] INFO: Enabled item pipelines:
['web_news.pipelines.MongoDBPipeline']
2017-03-18 14:45:18 [scrapy.core.engine] INFO: Spider opened
2017-03-18 14:45:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-18 14:50:20 [guangxidj] INFO: wait 6 spiders to stop
2017-03-18 14:50:20 [guangxidj] INFO: wait 5 spiders to stop
2017-03-18 14:50:20 [guangxidj] INFO: wait 4 spiders to stop
2017-03-18 14:50:20 [guangxidj] INFO: wait 3 spiders to stop
2017-03-18 14:50:22 [guangxidj] INFO: wait 2 spiders to stop
2017-03-18 14:50:22 [guangxidj] INFO: wait 1 spiders to stop
2017-03-18 14:50:22 [guangxidj] INFO: all slave spider exit
2017-03-18 14:50:22 [guangxidj] INFO: publish to restart
2017-03-18 14:50:22 [guangxidj] INFO: restart
2017-03-18 14:50:22 [guangxidj] INFO: get key 1
2017-03-18 14:50:22 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-03-18 14:55:22 [guangxidj] INFO: wait 6 spiders to stop
2017-03-18 14:55:22 [guangxidj] INFO: wait 5 spiders to stop
2017-03-18 14:55:22 [guangxidj] INFO: wait 4 spiders to stop
2017-03-18 14:55:22 [guangxidj] INFO: wait 3 spiders to stop
2017-03-18 14:55:22 [guangxidj] INFO: wait 2 spiders to stop
2017-03-18 14:55:22 [guangxidj] INFO: wait 1 spiders to stop
2017-03-18 14:55:22 [guangxidj] INFO: all slave spider exit
2017-03-18 14:55:22 [guangxidj] INFO: publish to restart
2017-03-18 14:55:22 [guangxidj] INFO: restart
2017-03-18 14:55:22 [guangxidj] INFO: get key 1
2017-03-18 14:55:22 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
